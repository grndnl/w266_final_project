{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grndnl/w266_final_project/blob/main/Understanding_if_elements_are_part_of_an_assembly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_6dkdVr2YarJ"
      },
      "source": [
        "# Predicting whether two sets of assembly names are from the same assembly"
      ],
      "id": "_6dkdVr2YarJ"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thKnoKjAYarK",
        "outputId": "6e154e99-7597-40bc-feca-c3ea25b18c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "import os, re\n",
        "from pathlib import Path\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import random\n",
        "!pip install transformers\n",
        "from transformers import AutoTokenizer, TFAutoModel, BertTokenizer, TFBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint"
      ],
      "id": "thKnoKjAYarK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MZFXEOVUYarM"
      },
      "source": [
        "# Preprocess data"
      ],
      "id": "MZFXEOVUYarM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yN6YQRV9YarN"
      },
      "source": [
        "### Pre-process data for task"
      ],
      "id": "yN6YQRV9YarN"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zr2wLdEZDMe",
        "outputId": "ea8dd6ba-f3ce-491c-f13c-c5aea2d488db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "6Zr2wLdEZDMe"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "2Hr6_RgkYarN"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/My Drive/W266/data_02.feather\"\n",
        "data = pd.read_feather(data_path)"
      ],
      "id": "2Hr6_RgkYarN"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lZ_lXz0iYarN",
        "outputId": "31c69945-5fb4-48f3-9eb5-cf95105e5717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         assembly_name                                         part_names\n",
              "0          Lava Lamp 2                  [Blob3, Blob2, Blob1, Glass, Cap]\n",
              "1  Sample - Headphones  [Pivot hinge, Headphone hinge, Telescope hinge...\n",
              "4           Coffee Mug                                         [Mug, Lid]\n",
              "5  Dave's Handsome Mug                                [Lid, Seal, Vessel]\n",
              "9    Mechanical Pencil  [Eraser, Pencil Lead, Rubber Grip, Gripper Rod..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b60e9605-02fb-4bc5-b81a-7db0dea07909\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assembly_name</th>\n",
              "      <th>part_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lava Lamp 2</td>\n",
              "      <td>[Blob3, Blob2, Blob1, Glass, Cap]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sample - Headphones</td>\n",
              "      <td>[Pivot hinge, Headphone hinge, Telescope hinge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coffee Mug</td>\n",
              "      <td>[Mug, Lid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dave's Handsome Mug</td>\n",
              "      <td>[Lid, Seal, Vessel]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mechanical Pencil</td>\n",
              "      <td>[Eraser, Pencil Lead, Rubber Grip, Gripper Rod...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b60e9605-02fb-4bc5-b81a-7db0dea07909')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b60e9605-02fb-4bc5-b81a-7db0dea07909 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b60e9605-02fb-4bc5-b81a-7db0dea07909');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "data = data.dropna(subset=[\"assembly_name\", \"part_names\"])\n",
        "data = data.drop(columns=[\"assembly_id\", 'assembly_description'])\n",
        "#data = data.drop(columns=[\"assembly_id\"]) This one is no longer necesary as we prove doesnt add much value\n",
        "data.head()"
      ],
      "id": "lZ_lXz0iYarN"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkeh2DbNYarN",
        "outputId": "1b3a21dc-c9e5-4b8e-dd03-5f289af9d459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tot: 88886\n",
            "Unique: 67834\n",
            "\n",
            "After dedup: 61725\n",
            "Unique: 54034\n"
          ]
        }
      ],
      "source": [
        "# Deduplicate\n",
        "print(f\"Tot: {len(data)}\")\n",
        "print(f\"Unique: {len(data['assembly_name'].unique())}\")\n",
        "data = data[~data['part_names'].apply(tuple).duplicated()]\n",
        "print(f\"\\nAfter dedup: {len(data)}\")\n",
        "print(f\"Unique: {len(data['assembly_name'].unique())}\")"
      ],
      "id": "Mkeh2DbNYarN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "P7nik7vQYarN"
      },
      "source": [
        "### Clean assembly names"
      ],
      "id": "P7nik7vQYarN"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9FD6exYnYarN"
      },
      "outputs": [],
      "source": [
        "def process_assembly_names(string):\n",
        "    string = string.replace('.x_t', '')\n",
        "    string = string.replace('.stp', '')\n",
        "    string = string.replace('.step', '')\n",
        "    string = string.replace('.zip', '')\n",
        "    string = string.replace('.dwg', '')\n",
        "    string = ' '.join(re.findall('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', string))  # splits camelCase into camel case\n",
        "    string = ' '.join(re.split('(\\s+|^)([A-Za-z]+)\\d+(\\s+|$)', string))  # removes number at the end\n",
        "    string = string.lower()\n",
        "    string = string.replace('_', ' ')\n",
        "    string = string.replace('-', ' ')\n",
        "    string = string.replace('[', ' ')\n",
        "    string = string.replace(']', ' ')\n",
        "    string = string.replace('(', ' ')\n",
        "    string = string.replace(')', ' ')\n",
        "    string = string.replace('?', ' ')\n",
        "    string = string.replace('*', ' ')\n",
        "    string = string.replace('copy of', ' ')\n",
        "    string = string.replace('copy', ' ')\n",
        "    string = string.replace('sample', '')\n",
        "    string = string.replace('2', '')\n",
        "    string = string.replace('tutorial', '')\n",
        "    string = \" \".join(string.split())\n",
        "\n",
        "    return string\n",
        "\n",
        "\n",
        "data['assembly_name_clean'] = data.apply(lambda row: process_assembly_names(row.assembly_name), axis=1)"
      ],
      "id": "9FD6exYnYarN"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuLrV2NlYarO",
        "outputId": "adefcf5d-6911-416b-d37b-c7a16ca08451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dedup: 61725\n",
            "Unique: 49240\n"
          ]
        }
      ],
      "source": [
        "print(f\"After dedup: {len(data)}\")\n",
        "print(f\"Unique: {len(data['assembly_name_clean'].unique())}\")"
      ],
      "id": "VuLrV2NlYarO"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wNk-Ltgh58T",
        "outputId": "4e6e7bd0-90a2-4ebc-9bca-9d77c36dfc54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dedup: 61725\n",
            "Unique: 49240\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"After dedup: {len(data)}\")\n",
        "print(f\"Unique: {len(data['assembly_name_clean'].unique())}\")"
      ],
      "id": "3wNk-Ltgh58T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_7ZgEQD_YarO"
      },
      "source": [
        "### Clean part names"
      ],
      "id": "_7ZgEQD_YarO"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "c_iFXM10YarO"
      },
      "outputs": [],
      "source": [
        "def process_part_names(part_list):\n",
        "    part_names = []\n",
        "    for string in part_list:\n",
        "        if \"MANIFOLD_SOLID_BREP\" in string:\n",
        "            return np.nan\n",
        "        string = string.replace('.x_t', '')\n",
        "        string = string.replace('.stp', '')\n",
        "        string = string.replace('.step', '')\n",
        "        string = string.replace('.dwg', '')\n",
        "        string = string.replace('.zip', '')\n",
        "        string = ' '.join(re.findall('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', string))  # splits camelCase into camel case\n",
        "        string = ' '.join(re.split('(\\s+|^)([A-Za-z]+)\\d+(\\s+|$)', string))  # removes number at the end\n",
        "        string = string.lower()\n",
        "        string = string.replace('_', ' ')\n",
        "        string = string.replace('-', ' ')\n",
        "        string = string.replace('[', ' ')\n",
        "        string = string.replace(']', ' ')\n",
        "        string = string.replace('(', ' ')\n",
        "        string = string.replace(')', ' ')\n",
        "        string = string.replace('?', ' ')\n",
        "        string = string.replace('*', ' ')\n",
        "        string = string.replace('copy of', ' ')\n",
        "        string = string.replace('copy', ' ')\n",
        "        string = \" \".join(string.split())\n",
        "\n",
        "        part_names.append(string)\n",
        "\n",
        "    random.shuffle(part_names)\n",
        "    return list(set(part_names))\n",
        "\n",
        "\n",
        "data['part_names_clean'] = data.apply(lambda row: process_part_names(row.part_names), axis=1)\n",
        "data.dropna(subset=['part_names_clean'], inplace=True)"
      ],
      "id": "c_iFXM10YarO"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tP6jd8HcZqkK",
        "outputId": "fd4d8927-adfb-4802-9d76-99c826adfa89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         assembly_name                                         part_names  \\\n",
              "0          Lava Lamp 2                  [Blob3, Blob2, Blob1, Glass, Cap]   \n",
              "1  Sample - Headphones  [Pivot hinge, Headphone hinge, Telescope hinge...   \n",
              "4           Coffee Mug                                         [Mug, Lid]   \n",
              "5  Dave's Handsome Mug                                [Lid, Seal, Vessel]   \n",
              "9    Mechanical Pencil  [Eraser, Pencil Lead, Rubber Grip, Gripper Rod...   \n",
              "\n",
              "   assembly_name_clean                                   part_names_clean  \n",
              "0            lava lamp                                 [cap, blob, glass]  \n",
              "1           headphones  [upper band, pivot hinge, telescope hinge, hea...  \n",
              "4           coffee mug                                         [mug, lid]  \n",
              "5  dave's handsome mug                                [vessel, seal, lid]  \n",
              "9    mechanical pencil  [button release, eraser, pencil lead, gripper ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02710d64-81af-47c0-907c-cf421105251c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assembly_name</th>\n",
              "      <th>part_names</th>\n",
              "      <th>assembly_name_clean</th>\n",
              "      <th>part_names_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lava Lamp 2</td>\n",
              "      <td>[Blob3, Blob2, Blob1, Glass, Cap]</td>\n",
              "      <td>lava lamp</td>\n",
              "      <td>[cap, blob, glass]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sample - Headphones</td>\n",
              "      <td>[Pivot hinge, Headphone hinge, Telescope hinge...</td>\n",
              "      <td>headphones</td>\n",
              "      <td>[upper band, pivot hinge, telescope hinge, hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coffee Mug</td>\n",
              "      <td>[Mug, Lid]</td>\n",
              "      <td>coffee mug</td>\n",
              "      <td>[mug, lid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dave's Handsome Mug</td>\n",
              "      <td>[Lid, Seal, Vessel]</td>\n",
              "      <td>dave's handsome mug</td>\n",
              "      <td>[vessel, seal, lid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mechanical Pencil</td>\n",
              "      <td>[Eraser, Pencil Lead, Rubber Grip, Gripper Rod...</td>\n",
              "      <td>mechanical pencil</td>\n",
              "      <td>[button release, eraser, pencil lead, gripper ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02710d64-81af-47c0-907c-cf421105251c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02710d64-81af-47c0-907c-cf421105251c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02710d64-81af-47c0-907c-cf421105251c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "data.head()"
      ],
      "id": "tP6jd8HcZqkK"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ABNDqb8HYarO",
        "outputId": "0fb9c804-2eea-4096-fc47-f87878effbb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         assembly_name                                         part_names  \\\n",
              "0          Lava Lamp 2                  [Blob3, Blob2, Blob1, Glass, Cap]   \n",
              "1  Sample - Headphones  [Pivot hinge, Headphone hinge, Telescope hinge...   \n",
              "4           Coffee Mug                                         [Mug, Lid]   \n",
              "5  Dave's Handsome Mug                                [Lid, Seal, Vessel]   \n",
              "9    Mechanical Pencil  [Eraser, Pencil Lead, Rubber Grip, Gripper Rod...   \n",
              "\n",
              "   assembly_name_clean                                   part_names_clean  \n",
              "0            lava lamp                                 [cap, blob, glass]  \n",
              "1           headphones  [upper band, pivot hinge, telescope hinge, hea...  \n",
              "4           coffee mug                                         [mug, lid]  \n",
              "5  dave's handsome mug                                [vessel, seal, lid]  \n",
              "9    mechanical pencil  [button release, eraser, pencil lead, gripper ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9ba79bb-a2a7-4453-92d5-1bb2c7ffed54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assembly_name</th>\n",
              "      <th>part_names</th>\n",
              "      <th>assembly_name_clean</th>\n",
              "      <th>part_names_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lava Lamp 2</td>\n",
              "      <td>[Blob3, Blob2, Blob1, Glass, Cap]</td>\n",
              "      <td>lava lamp</td>\n",
              "      <td>[cap, blob, glass]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sample - Headphones</td>\n",
              "      <td>[Pivot hinge, Headphone hinge, Telescope hinge...</td>\n",
              "      <td>headphones</td>\n",
              "      <td>[upper band, pivot hinge, telescope hinge, hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coffee Mug</td>\n",
              "      <td>[Mug, Lid]</td>\n",
              "      <td>coffee mug</td>\n",
              "      <td>[mug, lid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dave's Handsome Mug</td>\n",
              "      <td>[Lid, Seal, Vessel]</td>\n",
              "      <td>dave's handsome mug</td>\n",
              "      <td>[vessel, seal, lid]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mechanical Pencil</td>\n",
              "      <td>[Eraser, Pencil Lead, Rubber Grip, Gripper Rod...</td>\n",
              "      <td>mechanical pencil</td>\n",
              "      <td>[button release, eraser, pencil lead, gripper ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ba79bb-a2a7-4453-92d5-1bb2c7ffed54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9ba79bb-a2a7-4453-92d5-1bb2c7ffed54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9ba79bb-a2a7-4453-92d5-1bb2c7ffed54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "data.head()"
      ],
      "id": "ABNDqb8HYarO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rErdMnhBYarO"
      },
      "source": [
        "## Create sentences"
      ],
      "id": "rErdMnhBYarO"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yRZlXgBYarO",
        "outputId": "291d4463-0edc-40ea-b860-ac4663116676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61601/61601 [00:03<00:00, 17062.34it/s]\n"
          ]
        }
      ],
      "source": [
        "sentence_pairs = []\n",
        "for index, row in tqdm(data.iterrows(), total=len(data)):\n",
        "    num_parts = len(row['part_names_clean'])\n",
        "    if num_parts > 1:\n",
        "        sentence_1 = f\"An assembly named '{row['assembly_name_clean']}' containing the following parts: \"\n",
        "        for part_name in row['part_names_clean'][:num_parts-1]:\n",
        "                sentence_1 += f\"{part_name}, \"\n",
        "\n",
        "\n",
        "        sentence_2 = ''\n",
        "        for part_name in row['part_names_clean'][num_parts-1:]:\n",
        "            sentence_2 += f\"{part_name}, \"\n",
        "        sentence_2 = sentence_2[:-2] + \".\"\n",
        "\n",
        "        sentence_pairs.append([sentence_1, sentence_2])\n"
      ],
      "id": "3yRZlXgBYarO"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3dNllJ7YarP",
        "outputId": "45ad59c1-42e0-4675-81e7-e6420391c9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40240\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(sentence_pairs)\n",
        "print(len(sentence_pairs))\n",
        "#pprint(sentence_pairs[:50])"
      ],
      "id": "W3dNllJ7YarP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_c9jlWbvYarP"
      },
      "source": [
        "# Train test split"
      ],
      "id": "_c9jlWbvYarP"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Yto-FpiEYarP"
      },
      "outputs": [],
      "source": [
        "positive_samples = sentence_pairs[:len(sentence_pairs)//2]\n",
        "negative_samples = sentence_pairs[len(sentence_pairs)//2:]\n",
        "#positive_samples = sentence_pairs[:len(sentence_pairs)]\n",
        "#negative_samples = sentence_pairs[:len(sentence_pairs)]"
      ],
      "id": "Yto-FpiEYarP"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "popc4NdeYarP",
        "outputId": "d1d32e58-8ca8-4c0b-9b75-28da08a8c2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"An assembly named 'c coupler' containing the following parts: coupler, nut, \", 'nut 14/17.']\n",
            "[\"An assembly named 'drone king of the hill' containing the following parts: light sensor, plug, tube, platform, \", 'casing.']\n",
            "[\"An assembly named 'c coupler' containing the following parts: coupler, nut, \", 'female connector.']\n"
          ]
        }
      ],
      "source": [
        "# Scramble the negative samples while maintaining the sentence pair order\n",
        "print(negative_samples[1])\n",
        "print(positive_samples[1])\n",
        "\n",
        "negative_sentence_1 = [pair[0] for pair in negative_samples]\n",
        "negative_sentence_2 = [pair[1] for pair in negative_samples]\n",
        "random.shuffle(negative_sentence_2)\n",
        "negative_samples = [list(x) for x in zip(negative_sentence_1, negative_sentence_2)]\n",
        "print(negative_samples[1])"
      ],
      "id": "popc4NdeYarP"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "MQej_EpBYarP"
      },
      "outputs": [],
      "source": [
        "# Create labels: 1 = positive, 0 = negative\n",
        "positive_samples = [(sample, 1) for sample in positive_samples]\n",
        "negative_samples = [(sample, 0) for sample in negative_samples]\n",
        "\n",
        "sentence_pairs = positive_samples + negative_samples"
      ],
      "id": "MQej_EpBYarP"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "XXHW93biXVVR"
      },
      "outputs": [],
      "source": [
        "#negative_samples"
      ],
      "id": "XXHW93biXVVR"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4TJoxc5YarQ",
        "outputId": "11e1b6de-1ed4-4dd9-e73c-614b6742ffd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train: 32192\n",
            "Length of test: 8048\n"
          ]
        }
      ],
      "source": [
        "train, test = train_test_split(sentence_pairs, test_size=0.2)\n",
        "print(f\"Length of train: {len(train)}\")\n",
        "print(f\"Length of test: {len(test)}\")"
      ],
      "id": "b4TJoxc5YarQ"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "BpvN2L9GYarQ"
      },
      "outputs": [],
      "source": [
        "#train[:5]"
      ],
      "id": "BpvN2L9GYarQ"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "nC84MKouYarQ"
      },
      "outputs": [],
      "source": [
        "# Save out train data\n",
        "\n",
        "train_data_path = \"/content/drive/My Drive/W266/entailment/train_entailment.csv\"\n",
        "train_df = pd.DataFrame(train)\n",
        "\n",
        "if not os.path.exists(Path(train_data_path).parent):\n",
        "    os.mkdir(Path(train_data_path).parent)\n",
        "\n",
        "train_df.to_csv(train_data_path, index=False)"
      ],
      "id": "nC84MKouYarQ"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "00bee460"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, tokenizer, max_length=128):\n",
        "    labels = [item[1] for item in data]\n",
        "    sentence_pairs = [item[0] for item in data]\n",
        "\n",
        "    # With BERT tokenizer's batch_encode_plus, sentence pairs are\n",
        "    # encoded together and separated by [SEP] token.\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        sentence_pairs,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_tensors=\"tf\"\n",
        "    )\n",
        "\n",
        "    # Extract encoded features and labels, add to corresponding lists\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "    \n",
        "    return [input_ids, attention_masks, token_type_ids], np.array(labels)"
      ],
      "id": "00bee460"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vN53eup0YarQ"
      },
      "source": [
        "# Construct the model"
      ],
      "id": "vN53eup0YarQ"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc7eDKwbYarQ",
        "outputId": "ce880004-3747-4dd9-8f94-6ee2dac8e34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "bert_model_name='bert-base-uncased'\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "#bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFAutoModel.from_pretrained(bert_model_name)\n",
        "bert_model.trainable = False"
      ],
      "id": "uc7eDKwbYarQ"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "rADBsc6CYarQ"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model(bert_model, max_length=128):\n",
        "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
        "    attention_masks = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_masks')\n",
        "    token_type_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
        "    sequence_output=bert_output[1]\n",
        "    #sequence_output = bert_output.last_hidden_state\n",
        "\n",
        "    #attn_output = layers.MultiHeadAttention(num_heads=8, key_dim=16)(sequence_output, sequence_output)\n",
        "    #max_pool = layers.GlobalMaxPooling1D()(sequence_output, sequence_output)\n",
        "    dropout_output = layers.Dropout(0)(sequence_output)\n",
        "    final_output = layers.Dense(1, activation=\"sigmoid\")(dropout_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks, token_type_ids],\n",
        "                                  outputs=[final_output])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "id": "rADBsc6CYarQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy97Fg8X9l2A"
      },
      "outputs": [],
      "source": [],
      "id": "Gy97Fg8X9l2A"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rbsd9b9cuecm"
      },
      "outputs": [],
      "source": [
        "def build_New_model(bert_model, train_layers=-1, max_length=128):\n",
        "\n",
        "    if train_layers == -1:\n",
        "        # Freeze all layers of pre-trained BERT model\n",
        "        bert_model.trainable = False\n",
        "\n",
        "    else:\n",
        "        # Restrict training to the train_layers outer transformer layers\n",
        "        retrain_layers = []\n",
        "\n",
        "        for retrain_layer_number in range(train_layers):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code)\n",
        "          \n",
        "        \n",
        "        print('retrain layers: ', retrain_layers)\n",
        "\n",
        "        for w in bert_model.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                print('freezing: ', w)\n",
        "                w._trainable = False\n",
        "\n",
        "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
        "    attention_masks = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_masks')\n",
        "    token_type_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
        "    sequence_output=bert_output[1]\n",
        "    #sequence_output = bert_output.last_hidden_state\n",
        "\n",
        "    #attn_output = layers.MultiHeadAttention(num_heads=4, key_dim=100)(sequence_output, sequence_output)\n",
        "    #max_pool = layers.GlobalMaxPooling1D()(attn_output)\n",
        "    #dropout_output = layers.Dropout(0.3)(max_pool)\n",
        "    final_output = layers.Dense(1, activation=\"sigmoid\")(sequence_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks, token_type_ids],\n",
        "                                  outputs=[final_output])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "id": "rbsd9b9cuecm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WJLUPcLYarS"
      },
      "outputs": [],
      "source": [
        "def build_New_model2(bert_model, max_length=128, hidden_dim=256):\n",
        "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
        "    attention_masks = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_masks')\n",
        "    token_type_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
        "    sequence_output = bert_output.last_hidden_state\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_layer')(sequence_output)\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_dim/2, activation='relu', name='hidden_layer2')(hidden)\n",
        "\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=8, key_dim=100)(hidden, hidden)\n",
        "    max_pool = layers.GlobalMaxPooling1D()(attn_output)\n",
        "    dropout_output = layers.Dropout(0.3)(max_pool)\n",
        "    final_output = layers.Dense(1, activation=\"sigmoid\")(dropout_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks, token_type_ids],\n",
        "                                  outputs=[final_output])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "id": "7WJLUPcLYarS"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "pqtlNbOk4175"
      },
      "outputs": [],
      "source": [
        "def build_New_model3(bert_model, max_length=128, hidden_dim=256):\n",
        "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
        "    attention_masks = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_masks')\n",
        "    token_type_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='token_type_ids')\n",
        "\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids)\n",
        "    sequence_output = bert_output.last_hidden_state\n",
        "    print(sequence_output)\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=8, key_dim=32)(sequence_output, sequence_output)\n",
        "\n",
        "    #hidden = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_layer')(attn_output)\n",
        "\n",
        "    #hidden = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_layer2')(hidden)\n",
        "\n",
        "    max_pool = layers.GlobalMaxPooling1D()(attn_output)\n",
        "    dropout_output = layers.Dropout(0)(max_pool)\n",
        "    final_output = layers.Dense(1, activation=\"sigmoid\")(dropout_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks, token_type_ids],\n",
        "                                  outputs=[final_output])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "id": "pqtlNbOk4175"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Sa7HN6bMGuoM"
      },
      "outputs": [],
      "source": [
        "model = build_baseline_model(bert_model, max_length=256)\n",
        "#model1 = build_baseline_model(bert_model, max_length=128)\n"
      ],
      "id": "Sa7HN6bMGuoM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyVUBtt4DpvT"
      },
      "outputs": [],
      "source": [
        "model1=build_baseline_model(bert_model, max_length=256)"
      ],
      "id": "IyVUBtt4DpvT"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH_fMliNHFHF",
        "outputId": "d040d80a-d2d2-45df-db26-44419e58d8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 256, 768), dtype=tf.float32, name=None), name='tf_bert_model_2/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model_2'\")\n"
          ]
        }
      ],
      "source": [
        "model2= build_New_model3(bert_model, max_length=256, hidden_dim=256)"
      ],
      "id": "gH_fMliNHFHF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyItJVOIvVDm"
      },
      "outputs": [],
      "source": [
        "#keras.utils.plot_model(model1, show_shapes=True, dpi=90)"
      ],
      "id": "wyItJVOIvVDm"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "4b82e1a2"
      },
      "outputs": [],
      "source": [
        "class SNLIDataGeneratorFromFile(tf.keras.utils.Sequence):\n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 data_filename,\n",
        "                 max_length=128,\n",
        "                 batch_size=32,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.data_filename = data_filename\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_start = idx * self.batch_size\n",
        "        batch_end = (idx + 1) * self.batch_size\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this batch\n",
        "        batch_idx_skip = self.row_order[:batch_start] + self.row_order[batch_end:]\n",
        "        train_data_df = pd.read_csv(self.data_filename, skiprows=batch_idx_skip)\n",
        "\n",
        "        train_data = []\n",
        "        for index, row in train_data_df.iterrows():\n",
        "            train_data.append((row[0], row[1]))\n",
        "\n",
        "        batch_data = preprocess_data(\n",
        "            train_data,\n",
        "            self.tokenizer,\n",
        "            self.max_length\n",
        "        )\n",
        "\n",
        "        return batch_data\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ],
      "id": "4b82e1a2"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "os_CX135Yd3J"
      },
      "outputs": [],
      "source": [
        "train_data_generator = SNLIDataGeneratorFromFile(\n",
        "    tokenizer=bert_tokenizer,\n",
        "    n_examples=len(train),\n",
        "    data_filename=train_data_path,\n",
        "    batch_size=16,\n",
        "    max_length=256\n",
        ")"
      ],
      "id": "os_CX135Yd3J"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "uRsIRO16YarR"
      },
      "outputs": [],
      "source": [
        "test_data = preprocess_data(\n",
        "    test, tokenizer=bert_tokenizer, max_length=256\n",
        ")"
      ],
      "id": "uRsIRO16YarR"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "yNjbSiWN_Xce"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/W266/entailment/'\n",
        "checkpoint_filepath = checkpoint_dir + 'weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True)"
      ],
      "id": "yNjbSiWN_Xce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hCG0YzqKb2w"
      },
      "source": [
        "## Train model"
      ],
      "id": "_hCG0YzqKb2w"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Ol8d4NomYarR"
      },
      "outputs": [],
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)"
      ],
      "id": "Ol8d4NomYarR"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wk7AeC8LmEgu"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n"
      ],
      "id": "wk7AeC8LmEgu"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Lt4BKhYarS",
        "outputId": "b3976903-1713-4a96-c784-a1d412feb9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2012/2012 [==============================] - 876s 435ms/step - loss: 0.6911 - accuracy: 0.5460 - val_loss: 0.5977 - val_accuracy: 0.6213\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_data_generator, validation_data=test_data, epochs=2,\n",
        "          callbacks=[model_checkpoint_callback])"
      ],
      "id": "w7Lt4BKhYarS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYCWXqHwKIfE"
      },
      "outputs": [],
      "source": [
        "#history=model1.fit(train_data_generator, validation_data=test_data, epochs=2,\n",
        "#          callbacks=[model_checkpoint_callback])"
      ],
      "id": "RYCWXqHwKIfE"
    },
    {
      "cell_type": "code",
      "source": [
        "#history=model2.fit(train_data_generator, validation_data=test_data, epochs=2,\n",
        "#          callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "WH2PlpMvcZ8G"
      },
      "id": "WH2PlpMvcZ8G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history=model2.fit(train_data_generator, validation_data=test_data, epochs=2,\n",
        "#          callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "YQcINyMYh8_6"
      },
      "id": "YQcINyMYh8_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjccB72gHa2o",
        "outputId": "61c2b817-07d3-421c-fc99-8da9a0a03b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2012/2012 [==============================] - 885s 440ms/step - loss: 0.5300 - accuracy: 0.7213 - val_loss: 0.6039 - val_accuracy: 0.6787\n"
          ]
        }
      ],
      "source": [
        "history=model2.fit(train_data_generator, validation_data=test_data, epochs=2,\n",
        "          callbacks=[model_checkpoint_callback])"
      ],
      "id": "vjccB72gHa2o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdomOlKqAZE-"
      },
      "outputs": [],
      "source": [
        "def make_plot(axs, history1, \n",
        "              history2, \n",
        "              y_lim_loss_lower=0.4, \n",
        "              y_lim_loss_upper=0.6,\n",
        "              y_lim_accuracy_lower=0.7, \n",
        "              y_lim_accuracy_upper=0.8,\n",
        "              model_1_name='model 1',\n",
        "              model_2_name='model 2',\n",
        "              \n",
        "             ):\n",
        "    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
        "\n",
        "    ax1 = axs[0, 0]\n",
        "    ax1.plot(history1.history['loss'])\n",
        "    ax1.plot(history1.history['val_loss'])\n",
        "    ax1.set_title('loss - ' + model_1_name)\n",
        "    ax1.set_ylabel('loss', bbox=box)\n",
        "    ax1.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n",
        "\n",
        "    ax3 = axs[1, 0]\n",
        "    ax3.set_title('accuracy - ' + model_1_name)\n",
        "    ax3.plot(history1.history['accuracy'])\n",
        "    ax3.plot(history1.history['val_accuracy'])\n",
        "    ax3.set_ylabel('accuracy', bbox=box)\n",
        "    ax3.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)\n",
        "\n",
        "\n",
        "    ax2 = axs[0, 1]\n",
        "    ax2.set_title('loss - ' + model_2_name)\n",
        "    ax2.plot(history2.history['loss'])\n",
        "    ax2.plot(history2.history['val_loss'])\n",
        "    ax2.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n",
        "\n",
        "    ax4 = axs[1, 1]\n",
        "    ax4.set_title('accuracy - ' + model_2_name)\n",
        "\n",
        "    # small adjustment to account for the 2 accuracy measures in the Weighted Averging Model with Attention\n",
        "    if 'classification_accuracy' in history2.history.keys():\n",
        "      ax4.plot(history2.history['classification_accuracy'])\n",
        "    else:\n",
        "      ax4.plot(history2.history['accuracy'])\n",
        "    \n",
        "    if 'val_classification_accuracy' in history2.history.keys():\n",
        "      ax4.plot(history2.history['val_classification_accuracy'])\n",
        "    else:\n",
        "      ax4.plot(history2.history['val_accuracy'])\n",
        "    ax4.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)"
      ],
      "id": "jdomOlKqAZE-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x5bilEl_mZn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "fig.subplots_adjust(left=0.2, wspace=0.6)\n",
        "make_plot(axs, history, history,model_1_name='Plots', model_2_name='Plots')\n",
        "\n",
        "fig.align_ylabels(axs[:, 1])\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "plt.show()"
      ],
      "id": "7x5bilEl_mZn"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}